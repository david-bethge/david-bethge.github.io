<!DOCTYPE HTML>
<html lang="en">
<meta http-equiv='cache-control' content='no-cache'> 
<meta http-equiv='expires' content='0'> 
<meta http-equiv='pragma' content='no-cache'>
<head>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LHYR833CDW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-LHYR833CDW');
  </script>
  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>David Bethge</title>
  <meta name="author" content="David Bethge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üöÄ</text></svg>">
  
  <link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.3/css/lightbox.min.css" rel="stylesheet" />
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&family=Poppins:wght@400;600;700&display=swap" rel="stylesheet">
</head>

<body>
  <header class="navbar">
    <div class="container nav-container">
      <nav>
        <a href="#about" class="nav-link">About</a>
        <a href="#research" class="nav-link">Research</a>
        <a href="#publications" class="nav-link">Publications</a>
        <a href="#patents" class="nav-link">Patents</a>
        <a href="#talks" class="nav-link">Talks</a>
      </nav>
      <div class="social-links-header">
        <a href="https://www.linkedin.com/in/david-bethge/" target="_blank" class="social-icon" title="LinkedIn">
          <img src="https://img.icons8.com/ios-filled/50/ffffff/linkedin.png" alt="LinkedIn">
        </a>
        <a href="https://scholar.google.com/citations?user=Ph0ocNoAAAAJ&hl=en&oi=ao" target="_blank" class="social-icon" title="Google Scholar">
          <img src="https://img.icons8.com/ios-filled/50/ffffff/google-scholar.png" alt="Google Scholar">
        </a>
      </div>
    </div>
  </header>

  <div class="main-container">
    <section id="about" class="section hero-section">
      <div class="profile-section">
        <div class="profile-image">
          <a href="images/davidbethge.jpeg" data-lightbox="profile-pic" data-title="David Bethge Profile Photo">
            <img alt="profile photo" src="images/davidbethge.jpeg">
          </a>
        </div>
        <div class="profile-info">
          <h1>David Bethge, Dr.</h1>
          <p>I am a Product Marketing Manager for high-resolution radar chips (mmWave ICs and radar processors) and high-resolution software at <a href="https://www.nxp.com/" target="_blank">NXP Semiconductors</a>. I love managing and executing projects or strategic initiatives in the field of technology. I am eager to connect with fascinating individuals and learn more about them.</p>
          <p>Previously, I worked at <a href="https://about.facebook.com/realitylabs/" target="_blank">Meta</a> as a researcher for machine learning and novel sensors for AR/VR input. I also worked as a Machine Learning Engineer and Innovation Manager for Emerging Technologies at <a href="https://www.porsche.com/" target="_blank">Porsche</a>.</p>
          <p>I obtained a PhD (Dr. rer. nat.) in Computer Science / Machine Learning at <a href="https://www.mathematik-informatik-statistik.uni-muenchen.de/index.html" target=" "_blank">LMU Munich</a> advised by <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>. I have a masters and bachelors degree in Industrial Engineering and Management from <a href = "https://www.kit.edu", > KIT</a> in Germany. In 2018/2019 I was a visiting researcher at <a href="https://www.ri.cmu.edu/" target="_blank">Carnegie Mellon University (CMU)</a> with <a href="https://www.ri.cmu.edu/ri-faculty/artur-w-dubrawski/" target="_blank">Artur Dubrawski</a>.</p>
        </div>
      </div>
    </section>

    <section id="research" class="section">
      <h2>Research</h2>
      <p>While I love working on cutting edge technologies, I am most interested in bringing them into products.</p>
      <p>I have written over 15 research papers and have over 10 patents. Visit <a href="https://scholar.google.com/citations?user=Ph0ocNoAAAAJ&hl=en&oi=ao" target="_blank">Google Scholar</a> for a complete and up-to-date list.</p>
    </section>

    <section id="publications" class="section">
      <h2>Publications</h2>
      <div class="publication-grid">
        <div class="publication-item">
          <div class="publication-image">
            <img src='images/happyrouting.png' alt="HappyRouting Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://arxiv.org/html/2401.15695v1" target="_blank">
              <h3>HappyRouting: Learning Emotion-Aware Route Trajectories for Scalable In-The-Wild Navigation</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, Daniel Bulanda, Adam Kozlowski, <a href="https://thomaskosch.com/" target="_blank">Thomas Kosch</a>, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>
            </p>
            <p class="journal"><em>arxiv</em>, 2024</p>
            <div class="links">
              <a href="https://arxiv.org/html/2401.15695v1" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Novel navigation algorithm that finds the "happy" route. Using contextual information and machine learning to predict most likely happy route elements everywhere in the world.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/phd_thesis.png' alt="PhD Thesis Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://edoc.ub.uni-muenchen.de/32270/1/Bethge_David.pdf" target="_blank">
              <h3>Machine learning systems for human emotional states</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>
            </p>
            <p class="journal"><em>Dissertation / PhD thesis</em>, 2023</p>
            <div class="links">
              <a href="https://edoc.ub.uni-muenchen.de/32270/1/Bethge_David.pdf" target="_blank">PhD thesis</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
        -->
            <div class="publication-abstract" style="display: none;">
              <p>This doctoral thesis explores various machine learning systems for understanding and predicting human emotional states using diverse sensor data, with a focus on real-world applications in driving contexts and physiological signals.</p>
            </div>
          </div>
        </div>
        
        <div class="publication-item">
          <div class="publication-image">
            <img src='images/imwut.jpg' alt="IMWUT Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2023technical.pdf" target="_blank">
              <h3>Technical design space analysis for unobtrusive driver emotion assessment using multi-domain context</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, Luis Falconeri Coelho, <a href="https://thomaskosch.com/" target="_blank">Thomas Kosch</a>, Satiyabooshan Murugaboopathy, <a href="https://code.berlin/de/team/ulrich-von-zadow/" target="_blank">Ulrich von Zadow</a>, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>
            </p>
            <p class="journal"><em>Ubicomp / IMWUT</em>, 2023</p>
            <div class="links">
              <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2023technical.pdf" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
        -->
            <div class="publication-abstract" style="display: none;">
              <p>Research explores non-intrusive prediction of driver emotions through contextual smartphone data, outperforming facial recognition by 7% in a study of 27 participants.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/itber.jpg' alt="ITBER Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2023interpretable.pdf" target="_blank">
              <h3>Interpretable Time-Dependent Convolutional Emotion Recognition with Contextual Data Streams</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, Constantin Patsch, <a href="https://philipph77.github.io/" target="_blank">Philipp Hallgarten</a>, <a href="https://thomaskosch.com/" target="_blank">Thomas Kosch</a>
            </p>
            <p class="journal"><em>CHI EA</em>, 2023</p>
            <div class="links">
              <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2023interpretable.pdf" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>-->
            <div class="publication-abstract" style="display: none;">
              <p>Convolution-based neural network for emotion classification with interpretable time- and feature-aware model decisions, tested on a real-world driving dataset.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/eusipco2023.jpg' alt="EUSIPCO Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://arxiv.org/pdf/2306.06522.pdf" target="_blank">
              <h3>TS-MoCo: Time-Series Momentum Contrast for Self-Supervised Physiological Representation Learning</h3>
            </a>
            <p class="authors">
              <a href="https://philipph77.github.io/" target="_blank">Philipp Hallgarten</a>, <strong>David Bethge</strong>, <a href="https://oozdenizci.github.io/" target="_blank">Ozan √ñzdenizci</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, <a href="https://www.professoren.tum.de/kasneci-enkelejda" target="_blank">Enkelejda Kasneci</a>
            </p>
            <p class="journal"><em>EUSIPCO</em>, 2023</p>
            <div class="links">
              <a href="https://arxiv.org/pdf/2306.06522.pdf" target="_blank">Paper</a>/
              <a href="https://github.com/philipph77/ts-moco" target="_blank">Code</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Self-supervised learning framework based on a transformer architecture for unlabeled physiological time-series, efficient for domain-agnostic systems in biomedical applications.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/smc.jpg' alt="SMC Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://arxiv.org/pdf/2207.08002.pdf" target="_blank">
              <h3>EEG2Vec: Learning Affective EEG Representations via Variational Autoencoders</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, <a href="https://philipph77.github.io/" target="_blank">Philipp Hallgarten</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, <a href="http://www.lewischuang.com/" target="_blank">Lewis L. Chuang</a>, <a href="https://oozdenizci.github.io/" target="_blank">Ozan √ñzdenizci</a>, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>
            </p>
            <p class="journal"><em>SMC</em>, 2022</p>
            <div class="links">
              <a href="https://arxiv.org/pdf/2207.08002.pdf" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>End-to-end representation learning framework for modeling user-specific affective representation from raw EEG.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/icassp.jpg' alt="ICASSP Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://arxiv.org/abs/2201.11613" target="_blank">
              <h3>Domain-Invariant Representation Learning from EEG with Private Encoders</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, <a href="https://philipph77.github.io/" target="_blank">Philipp Hallgarten</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, Ralf Mikut, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>, <a href="https://oozdenizci.github.io/" target="_blank">Ozan √ñzdenizci</a>
            </p>
            <p class="journal"><em>ICASSP</em>, 2022</p>
            <div class="links">
              <a href="https://arxiv.org/abs/2201.11613" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Multi-source deep learning network that is able to learn domain-invariant latent representation from multiple data-specific private encoders.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/embc.jpg' alt="EMBC Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://arxiv.org/pdf/2204.07777.pdf" target="_blank">
              <h3>Exploiting Multiple EEG Data Domains with Adversarial Learning</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, <a href="https://philipph77.github.io/" target="_blank">Philipp Hallgarten</a>, <a href="https://oozdenizci.github.io/" target="_blank">Ozan √ñzdenizci</a>, Ralf Mikut, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>
            </p>
            <p class="journal"><em>EMBC</em>, 2022</p>
            <div class="links">
              <a href="https://arxiv.org/pdf/2204.07777.pdf" target="_blank">Paper</a> /
              <a href="https://github.com/philipph77/ACSE-Framework" target="_blank">Code</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Enabling multi-source learning for EEG-based brain-computer interfaces via adversarial representation learning.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/teaserfig_vemotion.png' alt="VEmotion Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2021vemotion.pdf" target="_blank">
              <h3>VEmotion: Using Driving Context for Indirect Emotion Prediction in Real-Time</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, <a href="https://thomaskosch.com/" target="_blank">Thomas Kosch</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, <a href="http://www.lewischuang.com/" target="_blank">Lewis L. Chuang</a>, <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, Alexander Jagaciak, <a href="https://uni.ubicomp.net/as/" target="_blank">Albrecht Schmidt</a>
            </p>
            <p class="journal"><em>UIST</em>, 2021</p>
            <div class="links">
              <a href="https://thomaskosch.com/wp-content/papercite-data/pdf/bethge2021vemotion.pdf" target="_blank">Paper</a> /
              <a href="https://github.com/davebeght/VEmotion" target="_blank">Code</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Remote sensing system that analyzes traffic dynamics, environmental factors, in-vehicle context, and road characteristics to implicitly classify driver emotions.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/soundsride.png' alt="SoundsRide Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://3dvar.com/Kari2021SoundsRide.pdf" target="_blank">
              <h3>SoundsRide: Affordance-Synchronized Music Mixing for In-Car Audio Augmented Reality</h3>
            </a>
            <p class="authors">
              <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, Alexander Jagaciak, <strong>David Bethge</strong>, Reinhard Sch√ºtte, <a href="https://www.christianholz.net/" target="_blank">Christian Holz</a>
            </p>
            <p class="journal"><em>UIST</em>, 2021 (Best Paper Award)</p>
            <div class="links">
              <a href="https://3dvar.com/Kari2021SoundsRide.pdf" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
        -->
            <div class="publication-abstract" style="display: none;">
              <p>In-car audio augmented reality system that mixes music in real-time synchronized with sound affordances along the ride.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/ismar.png' alt="ISMAR Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://mkari.de/pubs/ismar2021-transformr.pdf" target="_blank">
              <h3>TransforMR: Pose-Aware Object Substitution for Composing Alternate Mixed Realities</h3>
            </a>
            <p class="authors">
              <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, <a href="http://grosse-puppendahl.com/" target="_blank">Tobias Grosse-Puppendahl</a>, Luis Falconeri Coelho, Andreas Fender, <strong>David Bethge</strong>, Reinhard Sch√ºtte, <a href="https://www.christianholz.net/" target="_blank">Christian Holz</a>
            </p>
            <p class="journal"><em>ISMAR</em>, 2021</p>
            <div class="links">
              <a href="https://mkari.de/pubs/ismar2021-transformr.pdf" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Mixed reality system for mobile devices that performs 3D-pose-aware object substitution to create meaningful mixed reality scenes.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/hminference.png' alt="HMInference Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://dl.acm.org/doi/abs/10.1145/3409118.3475145" target="_blank">
              <h3>HMInference: Inferring Multimodal HMI Interactions in Automotive Screens</h3>
            </a>
            <p class="authors">
              Jannik Wolf, Marco Wiedner, <a href="https://mkari.de/" target="_blank">Mohamed Kari</a>, <strong>David Bethge</strong>
            </p>
            <p class="journal"><em>AutoUI</em>, 2021</p>
            <div class="links">
              <a href="https://dl.acm.org/doi/abs/10.1145/3409118.3475145" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>System to predict interactions in the car HMI based on contextual CAN-BUS data.</p>
            </div>
          </div>
        </div>

        <div class="publication-item">
          <div class="publication-image">
            <img src='images/icdm.jpg' alt="ICDM Thumbnail">
          </div>
          <div class="publication-details">
            <a href="https://ieeexplore.ieee.org/document/8955539" target="_blank">
              <h3>Prognostication of Neurological Recovery by Analyzing Structural Breaks in EEG Data</h3>
            </a>
            <p class="authors">
              <strong>David Bethge</strong>, Jieshi Chen, Oliver Grothe, Jonathan Elmer, Artur Dubrawski
            </p>
            <p class="journal"><em>ICDM Workshop</em>, 2019</p>
            <div class="links">
              <a href="https://ieeexplore.ieee.org/document/8955539" target="_blank">Paper</a>
            </div>
            <!-- 
            <button class="toggle-description-btn">Show Abstract</button>
            -->
            <div class="publication-abstract" style="display: none;">
              <p>Unsupervised, multivariate yet interpretable structural break testing for prognostication of neurological recovery after cardiac arrest.</p>
            </div>
          </div>
        </div>
      </div> </section>

    <section id="patents" class="section">
      <h2>Patents</h2>
      <ul class="patent-list">
        <li>P1: DE/102022120257A1, ‚ÄúVerfahren, Wearable, Vorrichtung und Fahrzeug zur Emotionalisierung eines Fahrererlebnisses im Fahrzeug‚Äù (2024)</li>
        <li>P2: US/20240027215A1, ‚ÄúComputer-implemented method for determining a navigation route‚Äù (2024)</li>
        <li>P3: DE/102022113585A1, ‚ÄúComputerimplementiertes Verfahren zum Verbessern einer Performance einer Cockpit-Nutzerschnittstelle‚Äú(2023)</li>
        <li>P4: DE/102022110349A1, ‚ÄúVerfahren und Vorrichtung zur √úberwachung von Objekten‚Äù (2023)</li>
        <li>P5: DE/102022106797B3, ‚ÄúVerfahren zur automatischen Einstellung zumindest eines R√ºckspiegels eines Kraftfahrzeugs‚Äù (2023)</li>
        <li>P6: DE/102022106812B4, ‚ÄúComputerimplementiertes Verfahren zur Ermittlung eines Emotionszustandes einer Person in einem Kraftfahrzeug‚Äù (2024)</li>
        <li>P7: DE/102022104325A1, ‚ÄúVerfahren, System und Computerprogrammprodukt zur Erstellung einer Datenstruktur f√ºr auf k√ºnstlicher Intelligenz basierende Projekte‚Äù (2023)</li>
        <li>P8: DE102022104322A1, ‚ÄúVorrichtung und Verfahren zur Fahrerassistenz f√ºr ein Kraftfahrzeug, die Vorrichtung umfassendes Kraftfahrzeug‚Äù (2023)</li>
        <li>P9: DE/102021130939B3, ‚ÄúVorrichtungen und Verfahren zur gemeinsamen Routenf√ºhrung‚Äù (2023)</li>
        <li>P10: US/20230147024A1, ‚ÄúMethod and system for robust identification of a vehicle occupant‚Äù (2023)</li>
        <li>P11: DE/102021129108A1, ‚ÄúVerfahren, System und Computerprogrammprodukt zum Ausgeben von Ausgabewerten zur Analyse und/oder Bewertung und/oder Prozesssteuerung einer Entit√§t‚Äù (2023)</li>
        <li>P12: US/20230146013A1, ‚ÄúMethod for producing a model for automated prediction of interactions of a user with a user interface of a motor vehicle‚Äù (2023)</li>
        <li>P13: DE/102021129094A1, ‚ÄúVerfahren zum Ermitteln von Ersatzteilbedarf‚Äù (2023)</li>
        <li>P14: US/20230020786A1 ‚ÄúSystem for a motor vehicle and method for assessing the emotions of a driver of a motor vehicle‚Äù (2023)</li>
        <li>P15: DE/102021116641A1, ‚ÄúVerfahren, System und Computerprogramm zur interaktiven Auswahl und Wiedergabe von in Echtzeit erzeugten Audio- und/oder Videosequenzen in einem Kraftfahrzeug‚Äù (2022)</li>
        <li>P16: DE/102021110268A1, ‚ÄúVerfahren und System zur szenensynchronen Auswahl und Wiedergabe von Audiosequenzen f√ºr ein Kraftfahrzeug‚Äù (2022)</li>
      </ul>
    </section>

    <section id="talks" class="section">
      <h2>Talks / Lectures / Podcasts</h2>
      <p>I am regularly giving talks and keynotes about technology in general. Feel free to reach out.</p>
      <div class="talk-item">
        <div class="talk-image">
          <img src='images/4T4RInterference_talk.png' alt="IWPC Webinar" onerror="this.style.display='none'">
        </div>
        <div class="talk-details">
          <h3>AI-Driven DoA and Interference Mitigation on a 4T4R Radar SoC</h3>
          <p class="authors"><strong>Webinar</strong> @ IWPC: The International Wireless Industry Consortium</p>
          <p class="journal"><em>October 22, 2025</em></p>
          <div class="links">
            <a href="https://www.nxp.com/design/design-center/training/TIP-AI-DRIVEN-DOA-MITIGATION-4T4R-RADAR-SOC" target="_blank">Recording Link</a>
        </div>
        </div>
      </div>

      <div class="talk-item">
        <div class="talk-image">
          <img src='images/RadarPointCloudWebinar.png' alt="IWPC Webinar" onerror="this.style.display='none'"> 
        </div>
        <div class="talk-details">
          <h3>Radar AI - Deep Neural Networks for Enhanced Radar Point Cloud Generation</h3>
          <p class="authors"><strong>Webinar</strong> @ IWPC: The International Wireless Industry Consortium</p>
          <p class="journal"><em>November 13, 2024</em></p>
          <div class="links">
            <a href="https://www.nxp.com/design/design-center/training/TIP-RADAR-NETWORK-POINT-CLOUD?ticket=ST-132-j5lHQtKAem9P8K-4SADT5HvcG5w-nxp" target="_blank">Recording Link</a>
        </div>
        </div>
      </div>

      <div class="talk-item">
        <div class="talk-image">
          <img src='images/rosenblatt_algorithm.png' alt="Rosenblatt Algorithm Thumbnail">
        </div>
        <div class="talk-details">
          <h3>Data Science and Machine Learning Fundamentals</h3>
          <p class="authors"><strong>Cooperative State University Stuttgart / Karlsruhe (DHBW)</strong></p>
          <p class="journal"><em>Visiting Lecturer: 2018/2019/2020/2021</em></p>
          <div class="links">
            <a href="https://github.com/ferreirafabio/Intro_to_ML_DHBW" target="_blank">Lecture Materials</a>
        </div>
        </div>        
      </div>
    </section>


  </div> <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.3/js/lightbox-plus-jquery.min.js"></script>

  <script>
    // JavaScript for toggling publication abstracts
    document.addEventListener('DOMContentLoaded', function() {
      const buttons = document.querySelectorAll('.toggle-description-btn');

      buttons.forEach(button => {
        button.addEventListener('click', function() {
          const abstract = this.closest('.publication-details').querySelector('.publication-abstract');
          if (abstract) {
            if (abstract.style.display === 'none') {
              abstract.style.display = 'block';
              this.textContent = 'Hide Abstract';
            } else {
              abstract.style.display = 'none';
              this.textContent = 'Show Abstract';
            }
          }
        });
      });

      // Ensure Lightbox2 is configured if needed (optional)
      lightbox.option({
        'albumLabel': 'Image %1 of %2',
        'fadeDuration': 300,
        'resizeDuration': 200,
        'wrapAround': true
      });
    });
  </script>
</body>
</html>